{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e34dbf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "# import seaborn as sb\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, GlobalAveragePooling2D,AveragePooling2D\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras import models\n",
    "from keras.applications.resnet import layers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a933ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "ages = []\n",
    "    \n",
    "def preprocessing(given_img):\n",
    "    # given_img = cv2.cvtColor(given_img, cv2.COLOR_BGR2GRAY)  # converting image to grayscale.\n",
    "    # given_img = cv2.equalizeHist(given_img)\n",
    "    given_img = given_img / 255  # normalizing image.\n",
    "    given_img = cv2.resize(given_img, (64, 64))  # resizing it.\n",
    "    return given_img"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ff24dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Please provide your own image path\n",
    "path = \"C:/Users/mrsal/Github Repositories/Dataset/Age Recognition/UTKFace\"\n",
    "\n",
    "for image in os.listdir(path):\n",
    "    img = cv2.imread(path + \"/\" + image)\n",
    "    images.append(img)\n",
    "    ages.append(float(image.split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0797b354",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(images, ages, test_size=0.33, random_state=42)\n",
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)\n",
    "\n",
    "X_train = np.array([preprocessing(x) for x in X_train]).reshape(len(X_train), 64, 64, 3)\n",
    "X_valid = np.array([preprocessing(x) for x in X_valid]).reshape(len(X_valid), 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(15884, 64, 64, 3)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating and fitting the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        include_top=False, weights='imagenet', input_shape=input_shape\n",
    "    )\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='linear')(x)\n",
    "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Create the model and compile it\n",
    "input_shape = (64, 64, 3)\n",
    "model = create_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "497/497 [==============================] - 23s 28ms/step - loss: 365.9109 - mean_squared_error: 365.9109 - val_loss: 296.9227 - val_mean_squared_error: 296.9227\n",
      "Epoch 2/50\n",
      "497/497 [==============================] - 12s 24ms/step - loss: 284.0000 - mean_squared_error: 284.0000 - val_loss: 280.3196 - val_mean_squared_error: 280.3196\n",
      "Epoch 3/50\n",
      "497/497 [==============================] - 12s 24ms/step - loss: 267.9428 - mean_squared_error: 267.9428 - val_loss: 290.5996 - val_mean_squared_error: 290.5996\n",
      "Epoch 4/50\n",
      "497/497 [==============================] - 12s 24ms/step - loss: 254.2588 - mean_squared_error: 254.2588 - val_loss: 263.3978 - val_mean_squared_error: 263.3978\n",
      "Epoch 5/50\n",
      "497/497 [==============================] - 12s 24ms/step - loss: 239.8108 - mean_squared_error: 239.8108 - val_loss: 267.3148 - val_mean_squared_error: 267.3148\n",
      "Epoch 6/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 236.8174 - mean_squared_error: 236.8174 - val_loss: 229.3600 - val_mean_squared_error: 229.3600\n",
      "Epoch 7/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 230.2156 - mean_squared_error: 230.2156 - val_loss: 242.6482 - val_mean_squared_error: 242.6482\n",
      "Epoch 8/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 228.6990 - mean_squared_error: 228.6990 - val_loss: 231.9871 - val_mean_squared_error: 231.9871\n",
      "Epoch 9/50\n",
      "497/497 [==============================] - 12s 24ms/step - loss: 222.8432 - mean_squared_error: 222.8432 - val_loss: 219.3809 - val_mean_squared_error: 219.3809\n",
      "Epoch 10/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 221.5861 - mean_squared_error: 221.5861 - val_loss: 217.5535 - val_mean_squared_error: 217.5535\n",
      "Epoch 11/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 216.7031 - mean_squared_error: 216.7031 - val_loss: 240.1707 - val_mean_squared_error: 240.1707\n",
      "Epoch 12/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 212.8745 - mean_squared_error: 212.8745 - val_loss: 229.2067 - val_mean_squared_error: 229.2067\n",
      "Epoch 13/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 211.5709 - mean_squared_error: 211.5709 - val_loss: 258.3723 - val_mean_squared_error: 258.3723\n",
      "Epoch 14/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 214.2260 - mean_squared_error: 214.2260 - val_loss: 219.3548 - val_mean_squared_error: 219.3548\n",
      "Epoch 15/50\n",
      "497/497 [==============================] - 12s 24ms/step - loss: 212.1479 - mean_squared_error: 212.1479 - val_loss: 244.8119 - val_mean_squared_error: 244.8119\n",
      "Epoch 16/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 209.5127 - mean_squared_error: 209.5127 - val_loss: 230.8687 - val_mean_squared_error: 230.8687\n",
      "Epoch 17/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 209.9360 - mean_squared_error: 209.9360 - val_loss: 223.1085 - val_mean_squared_error: 223.1085\n",
      "Epoch 18/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 207.2620 - mean_squared_error: 207.2620 - val_loss: 228.5015 - val_mean_squared_error: 228.5015\n",
      "Epoch 19/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 207.3414 - mean_squared_error: 207.3414 - val_loss: 240.5348 - val_mean_squared_error: 240.5348\n",
      "Epoch 20/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 204.1583 - mean_squared_error: 204.1583 - val_loss: 217.3266 - val_mean_squared_error: 217.3266\n",
      "Epoch 21/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 203.7376 - mean_squared_error: 203.7376 - val_loss: 207.9515 - val_mean_squared_error: 207.9515\n",
      "Epoch 22/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 199.5999 - mean_squared_error: 199.5999 - val_loss: 221.5601 - val_mean_squared_error: 221.5601\n",
      "Epoch 23/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 206.0430 - mean_squared_error: 206.0430 - val_loss: 238.2504 - val_mean_squared_error: 238.2504\n",
      "Epoch 24/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 207.2490 - mean_squared_error: 207.2490 - val_loss: 204.5403 - val_mean_squared_error: 204.5403\n",
      "Epoch 25/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 200.0159 - mean_squared_error: 200.0159 - val_loss: 205.1635 - val_mean_squared_error: 205.1635\n",
      "Epoch 26/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 202.2064 - mean_squared_error: 202.2064 - val_loss: 208.6752 - val_mean_squared_error: 208.6752\n",
      "Epoch 27/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 200.6315 - mean_squared_error: 200.6315 - val_loss: 208.8543 - val_mean_squared_error: 208.8543\n",
      "Epoch 28/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 197.6897 - mean_squared_error: 197.6897 - val_loss: 211.5070 - val_mean_squared_error: 211.5070\n",
      "Epoch 29/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 199.8820 - mean_squared_error: 199.8820 - val_loss: 227.1400 - val_mean_squared_error: 227.1400\n",
      "Epoch 30/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 199.0091 - mean_squared_error: 199.0091 - val_loss: 208.0762 - val_mean_squared_error: 208.0762\n",
      "Epoch 31/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 200.6584 - mean_squared_error: 200.6584 - val_loss: 203.8038 - val_mean_squared_error: 203.8038\n",
      "Epoch 32/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 198.8187 - mean_squared_error: 198.8187 - val_loss: 203.4694 - val_mean_squared_error: 203.4694\n",
      "Epoch 33/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 192.4852 - mean_squared_error: 192.4852 - val_loss: 216.7508 - val_mean_squared_error: 216.7508\n",
      "Epoch 34/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 194.7916 - mean_squared_error: 194.7916 - val_loss: 206.7987 - val_mean_squared_error: 206.7987\n",
      "Epoch 35/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 193.7774 - mean_squared_error: 193.7774 - val_loss: 207.4987 - val_mean_squared_error: 207.4987\n",
      "Epoch 36/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 192.5720 - mean_squared_error: 192.5720 - val_loss: 200.1986 - val_mean_squared_error: 200.1986\n",
      "Epoch 37/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 190.8174 - mean_squared_error: 190.8174 - val_loss: 207.7326 - val_mean_squared_error: 207.7326\n",
      "Epoch 38/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 194.0218 - mean_squared_error: 194.0218 - val_loss: 199.5035 - val_mean_squared_error: 199.5035\n",
      "Epoch 39/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 192.1420 - mean_squared_error: 192.1420 - val_loss: 202.2083 - val_mean_squared_error: 202.2083\n",
      "Epoch 40/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 190.0809 - mean_squared_error: 190.0809 - val_loss: 199.1586 - val_mean_squared_error: 199.1586\n",
      "Epoch 41/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 189.3070 - mean_squared_error: 189.3070 - val_loss: 210.0971 - val_mean_squared_error: 210.0971\n",
      "Epoch 42/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 188.6391 - mean_squared_error: 188.6391 - val_loss: 204.2761 - val_mean_squared_error: 204.2761\n",
      "Epoch 43/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 187.2595 - mean_squared_error: 187.2595 - val_loss: 200.9545 - val_mean_squared_error: 200.9545\n",
      "Epoch 44/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 191.3114 - mean_squared_error: 191.3114 - val_loss: 199.6361 - val_mean_squared_error: 199.6361\n",
      "Epoch 45/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 189.1892 - mean_squared_error: 189.1892 - val_loss: 200.5606 - val_mean_squared_error: 200.5606\n",
      "Epoch 46/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 185.9025 - mean_squared_error: 185.9025 - val_loss: 218.1353 - val_mean_squared_error: 218.1353\n",
      "Epoch 47/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 189.0359 - mean_squared_error: 189.0359 - val_loss: 198.1920 - val_mean_squared_error: 198.1920\n",
      "Epoch 48/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 188.4271 - mean_squared_error: 188.4271 - val_loss: 201.1085 - val_mean_squared_error: 201.1085\n",
      "Epoch 49/50\n",
      "497/497 [==============================] - 12s 25ms/step - loss: 187.4229 - mean_squared_error: 187.4229 - val_loss: 198.7158 - val_mean_squared_error: 198.7158\n",
      "Epoch 50/50\n",
      "497/497 [==============================] - 13s 25ms/step - loss: 185.6738 - mean_squared_error: 185.6738 - val_loss: 226.2751 - val_mean_squared_error: 226.2751\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_valid, y_valid), callbacks=[stop])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_valid, y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the test set\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m test_loss, test_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_valid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_loss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_accuracy\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1459\u001B[0m   data_handler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler\n\u001B[0;32m   1460\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1461\u001B[0m   \u001B[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001B[39;00m\n\u001B[1;32m-> 1462\u001B[0m   data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1463\u001B[0m \u001B[43m      \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1464\u001B[0m \u001B[43m      \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1465\u001B[0m \u001B[43m      \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1466\u001B[0m \u001B[43m      \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1467\u001B[0m \u001B[43m      \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1468\u001B[0m \u001B[43m      \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1469\u001B[0m \u001B[43m      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1470\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1471\u001B[0m \u001B[43m      \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1472\u001B[0m \u001B[43m      \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1473\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1474\u001B[0m \u001B[43m      \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1476\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[0;32m   1477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1394\u001B[0m, in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1393\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1394\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1149\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1146\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution_value \u001B[38;5;241m=\u001B[39m steps_per_execution\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m   1148\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[1;32m-> 1149\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1153\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mds_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1163\u001B[0m strategy \u001B[38;5;241m=\u001B[39m ds_context\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[0;32m   1165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:243\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    233\u001B[0m              x,\n\u001B[0;32m    234\u001B[0m              y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    240\u001B[0m              shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    241\u001B[0m              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    242\u001B[0m   \u001B[38;5;28msuper\u001B[39m(TensorLikeDataAdapter, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(x, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 243\u001B[0m   x, y, sample_weights \u001B[38;5;241m=\u001B[39m \u001B[43m_process_tensorlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    244\u001B[0m   sample_weight_modes \u001B[38;5;241m=\u001B[39m broadcast_sample_weight_modes(\n\u001B[0;32m    245\u001B[0m       sample_weights, sample_weight_modes)\n\u001B[0;32m    247\u001B[0m   \u001B[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1042\u001B[0m, in \u001B[0;36m_process_tensorlike\u001B[1;34m(inputs)\u001B[0m\n\u001B[0;32m   1039\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001B[0;32m   1040\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m-> 1042\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_convert_numpy_and_scipy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mlist_to_tuple(inputs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1037\u001B[0m, in \u001B[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1035\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(x\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, np\u001B[38;5;241m.\u001B[39mfloating):\n\u001B[0;32m   1036\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m backend\u001B[38;5;241m.\u001B[39mfloatx()\n\u001B[1;32m-> 1037\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor_v2_with_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m _is_scipy_sparse(x):\n\u001B[0;32m   1039\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_valid, y_valid)\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Plot the training and validation loss/accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4814dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This code is in order to load the model. Make sure location and naming of a model is same, otherwise, please change below\n",
    "model = tf.keras.models.load_model(\"./CNN_MODEL_64.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}